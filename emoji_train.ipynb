{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, Flatten, Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils, print_summary\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11000, 2501)\n",
      "(2200, 2501)\n"
     ]
    }
   ],
   "source": [
    "training_images = 11000\n",
    "testing_images = 2200\n",
    "\n",
    "train_datadir = \"data/train\"\n",
    "test_datadir = \"data/test\"\n",
    "categories = {1:\"1\", 2:\"2\", 3:\"3\", 4:\"4\", 5:\"5\", 6:\"6\", 7:\"7\", 8:\"8\", 9:\"9\", 10:\"10\", 11:\"11\"}\n",
    "train_dataset = np.zeros(shape=(training_images,2501))\n",
    "test_dataset = np.zeros(shape=(testing_images,2501))\n",
    "\n",
    "counter = 0\n",
    "for category in categories:\n",
    "    path = os.path.join(train_datadir,categories[category])\n",
    "    label = np.array([category])\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (50,50))\n",
    "            te = image.flatten()\n",
    "            te = np.array(te)\n",
    "            te = np.concatenate((te, label), axis=0)\n",
    "            te = np.array(te)[np.newaxis]\n",
    "            #cv2.imwrite(\"newfan\"+str(i)+\".jpg\",image)\n",
    "            train_dataset[counter] = te\n",
    "            counter = counter + 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "counter = 0\n",
    "for category in categories:\n",
    "    path = os.path.join(test_datadir,categories[category])\n",
    "    label = np.array([category])\n",
    "    for img in os.listdir(path):\n",
    "        try:\n",
    "            image = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (50,50))\n",
    "            te = image.flatten()\n",
    "            te = np.array(te)\n",
    "            te = np.concatenate((te, label), axis=0)\n",
    "            te = np.array(te)[np.newaxis]\n",
    "            #cv2.imwrite(\"newfan\"+str(i)+\".jpg\",image)\n",
    "            test_dataset[counter] = te\n",
    "            counter = counter + 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "print(train_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_dataset)\n",
    "np.random.shuffle(test_dataset)\n",
    "\n",
    "X_train = train_dataset[:, 0:2500]\n",
    "Y_train = train_dataset[:, 2500]\n",
    "\n",
    "x_test = test_dataset[:, 0:2500]\n",
    "Y_test = test_dataset[:, 2500]\n",
    "\n",
    "x_train = X_train/255\n",
    "\n",
    "Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
    "y_train = Y_train.T\n",
    "\n",
    "Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
    "y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are taking an image of 50x50 for training purpose\n",
    "image_x = 50\n",
    "image_y = 50\n",
    "#to_categorical is an function which converts a matrix to a vector; in our case it basically gets the label which is an integer\n",
    "#and changes it to form of one_hot_encoding.\n",
    "#Check this link for more details->https://keras.io/utils/\n",
    "train_y = np_utils.to_categorical(y_train, dtype='int32')\n",
    "test_y = np_utils.to_categorical(y_test, dtype='int32')\n",
    "#adjusting the shape\n",
    "train_y = train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y = test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "x_train = x_train.reshape(x_train.shape[0], image_x, image_y, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], image_x, image_y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "(2200, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test_y[1])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 12\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=8, kernel_size=(3,3), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(3,3), padding='same'))\n",
    "    model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(3,3), padding='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.007)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.002)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    #saving the trained data is saved here\n",
    "    filepath='hand_emoji_v5.h5'\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint1]\n",
    "    #returning the model and the checkpoints of the saved(learned) data\n",
    "    return model, callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11000 samples, validate on 2200 samples\n",
      "Epoch 1/10\n",
      "11000/11000 [==============================] - 18s 2ms/step - loss: 3.5738 - acc: 0.9474 - val_loss: 1.6919 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.69187, saving model to hand_emoji_v6.h5\n",
      "Epoch 2/10\n",
      "11000/11000 [==============================] - 16s 1ms/step - loss: 1.0128 - acc: 0.9890 - val_loss: 0.7972 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.69187 to 0.79723, saving model to hand_emoji_v6.h5\n",
      "Epoch 3/10\n",
      "11000/11000 [==============================] - 15s 1ms/step - loss: 0.4662 - acc: 0.9908 - val_loss: 0.3720 - val_acc: 0.9991\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.79723 to 0.37203, saving model to hand_emoji_v6.h5\n",
      "Epoch 4/10\n",
      "11000/11000 [==============================] - 15s 1ms/step - loss: 0.3174 - acc: 0.9915 - val_loss: 0.4767 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.37203\n",
      "Epoch 5/10\n",
      "11000/11000 [==============================] - 15s 1ms/step - loss: 0.2315 - acc: 0.9928 - val_loss: 0.2916 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.37203 to 0.29158, saving model to hand_emoji_v6.h5\n",
      "Epoch 6/10\n",
      "11000/11000 [==============================] - 17s 2ms/step - loss: 0.2023 - acc: 0.9933 - val_loss: 0.2419 - val_acc: 0.9936\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.29158 to 0.24194, saving model to hand_emoji_v6.h5\n",
      "Epoch 7/10\n",
      "11000/11000 [==============================] - 16s 1ms/step - loss: 0.2138 - acc: 0.9915 - val_loss: 0.1885 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24194 to 0.18850, saving model to hand_emoji_v6.h5\n",
      "Epoch 8/10\n",
      "11000/11000 [==============================] - 15s 1ms/step - loss: 0.2071 - acc: 0.9918 - val_loss: 0.2687 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.18850\n",
      "Epoch 9/10\n",
      "11000/11000 [==============================] - 15s 1ms/step - loss: 0.1741 - acc: 0.9937 - val_loss: 0.2906 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.18850\n",
      "Epoch 10/10\n",
      "11000/11000 [==============================] - 15s 1ms/step - loss: 0.2061 - acc: 0.9924 - val_loss: 0.4228 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.18850\n",
      "CNN error: 1.45%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        12864     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 4, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 675,484\n",
      "Trainable params: 673,820\n",
      "Non-trainable params: 1,664\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model, callbacks_list = keras_model(image_x, image_y)\n",
    "model.fit(x_train, train_y, validation_data=(x_test, test_y), epochs=10, batch_size=64, callbacks=callbacks_list)\n",
    "scores = model.evaluate(x_test, test_y, verbose=0)\n",
    "print(\"CNN error: %.2f%%\" %(100 - scores[1] * 100))\n",
    "print_summary(model)\n",
    "model.save('hand_emoji_v5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
